<!--# include file="inc/header.html" -->
<div class="details-mian main" data-page="jy">
	<div class="details-page">
		<h4 class="details_header">
			机器人发展引发伦理讨论：怎样与人当好“合伙人
		</h4>
		<div class="details_line">
			<span class="details_time">2018-08-17</span>
			<div class="details_num">
				<!--<span class="details_eye"></span>-->
				<span>作者：人民日报</span>
			</div>
		</div>
		<div class="details_content">
			<div class="details_info">
				<div><p>15日，2018世界机器人大会在北京亦创国际会展中心开幕，展示全世界机器人产业的最新成果。为期3天的论坛上，由机器人发展引发的人工智能伦理和法律话题就是议题之一。
</p><p>应当建立规范机器人及其使用行为的法律框架
</p><p>在国际人工智能界，不少人认为人工智能会对人类产生巨大威胁，呼吁不要开发“人工智能自主武器”，警惕人工智能的潜在风险。他们讨论的人工智能，通常指的是未来能自主进化、有类人意识的“强人工智能”，而当前应用的多是擅长单项任务、完成人类指令的“弱人工智能”。即便如此，人工智能的迅速发展带来的挑战已经逐渐显现。
</p><p>为保护隐私，人们发布照片或视频时，会打上马赛克覆盖人脸，但美国一个研究小组开发了一套机器学习算法，通过训练，神经网络可以识别图像或视频中隐藏的信息。
</p><p>时下，一些机器人应用到儿童和老人陪护中。中国社会科学院哲学研究所研究员段伟文认为，机器人与儿童对答、给老人喂饭等行为看似简单，长期相处可能使人类对机器倾注感情、产生依赖，有必要设置防止过度依赖机器人的原则。此外，无人驾驶汽车发生交通事故怎么界定责任，医疗外科手术机器人出现意外怎样处置……随着智能机器人深入参与人类生活，专家认为，如何建立规范机器人及其使用行为的法律框架，成为人工智能和机器人产业发展无法回避的重要问题。
</p><p>清华大学人工智能研究院院长、中科院院士张钹曾表示，当前的人工智能与人类智能本质上是不同的。与人类相比，人工智能系统抗干扰能力差，推广能力弱，甚至可能犯大错。因此使用这样的人工智能系统需要小心。
</p><p>思考与智能机器的相处模式，控制不良影响
</p><p>人工智能的发展几经波折，也在不断进化。
</p><p>“人工智能及其智能化自动系统的普遍应用，不仅仅是一场结果未知的科技创新，更可能是人类文明史上影响深远的社会伦理试验。”段伟文说。
</p><p>北京师范大学哲学学院教授田海平表示，机器深度学习和算法体系，使得智能体具有了一种准人格或拟主体的特性。当前，“阿尔法狗”、医疗机器人“沃森”和智能伴侣虚拟机器人微软“小冰”仍属于“弱人工智能”，离真正的智能主体还比较远。即便如此，它们也已经呈现改变人类形态的发展趋势。未来假若“强人工智能”出现，并深度介入人类事务，那么，“我们必须提前思考人类如何与之相处的问题，控制它的不良影响。”田海平说：“人工智能是否以及如何为自己的行为负责，这仍然且始终是技术难题。”
</p><p>近年来，国际人工智能界日益重视人工智能中的伦理与法律问题，并推动相关技术标准及社会规范的研讨和制定。2017年1月，一个国际学术会议制定并发布了人工智能23条伦理原则，其中包括，人工智能研究的目标应该建立有益的智能，而不是无向的智能；人工智能系统的设计和运作应符合人类尊严，权利，自由和文化多样性的理念等。电气和电子工程师协会（IEEE）也颁布了《人工智能设计的伦理准则》，试图从工程设计和生产的角度，提出人工智能的伦理标准。
</p><p>我国人工智能研究及实践走在世界前列，但在相关机器伦理、立法研究和安全标准等方面起步相对较晚，近些年正在积极加强这些方面的研究。
</p><p>有专家表示，人工智能伦理法律等涉及科学界、企业界、哲学、法学等多个领域，有必要成立应对人工智能发展的联盟组织，吸纳各方面的力量，共同推进相关研究。
</p><p>运用算法，将人类道德规范体系嵌入智能机器
</p><p>段伟文说，人工智能系统的“拟主体性”，使得它们的行为可以看作是与人类伦理行为类似的拟伦理行为。因此，人工智能界在探讨能不能运用智能算法，将人类的价值观和道德规范体系嵌入到智能机器中。有专家认为，这既是人工智能未来愿景，也是当前面临的最大挑战。
</p><p>田海平说，把道德代码嵌入机器，是人工智能发展的必然趋势。缺少这一步，自动驾驶、无人机、助理机器人等智能体就不可能进入人类生活。机器在自主性上达到了人类高度后，它在做决策时，只有遵循道德算法，才能发展各种各样的功能。
</p><p>段伟文介绍，让机器符合人类道德规范，学界大体有3种设想：一是自上而下，即在智能体中预设一套伦理规范，如自动驾驶汽车应将撞车对他人造成的伤害降到最低；二是自下而上，即机器通过数据驱动，学习人类的伦理德道规范；三是人机交互，即让智能体用自然语言解释其决策，使人类能把握其复杂的逻辑并及时纠正可能存在的问题。
</p><p>“人工智能伦理研究目前没有一套普遍原则，因此可以从应用中遇到的实例出发，找到价值冲突点，讨论需要作哪些伦理考虑。”段伟文说，比如针对偏见，有必要追溯到机器学习的数据中，完善数据信息，并改进算法，让人工智能判断尽量客观公正，符合人类的价值观。
</p><p>尽管人工智能发展存在许多潜在问题，但更多人对技术应用的前景表示乐观。他们认为，人工智能能提供更安全、更智能的生活体验，不能因为技术潜在的不足而因噎废食，在提前布局，防范可能出现的挑战的同时，也要利用新技术来应对风险。
</p><p>以隐私安全为例，人工智能并不是隐私的天敌。北京大学信息科学技术学院教授郭耀说，利用人工智能技术能够应对一些常规方法难以应对的安全问题。比如，基于行为分析，人工智能可以快速检测出恶意软件，通过机器学习还能及时检测异常网络流量行为，预警黑客入侵，从而提升网络安全防御水平。
</p><p>张钹说，不管人工智能如何发展，基本理念应该不是用智能机器代替人，而是要协助人做好工作。人和机器各有优势，要互相了解才能实现人机协作，但人还是人机关系的主导者。如此，才可能将人工智能引向人机合作的发展道路。</p></div>
				
				<!--<div class="details_img">
					<img src="../static/imgs/JYnewImg.png" height="200px" alt="" />
				</div>-->
			</div>
		</div>
	</div>
</div>
<!--# include file="inc/footer.html" -->